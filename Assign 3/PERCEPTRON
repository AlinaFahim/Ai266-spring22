from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
train_df = pd.read_csv ('/content/drive/MyDrive/train.csv')
display(train_df)
#NORMALIZING DATASET
import numpy as np
train_df = pd.DataFrame(np.random.randint(1,100, 50).reshape(-1, 1))
train_norm = train_df.apply(lambda iterator: ((iterator.max() - iterator)/(iterator.max() - iterator.min())).round(2))
train_norm
#Libraries 
import pandas as pd
from sklearn.model_selection import train_test_split

train_df=pd.read_csv('/content/drive/MyDrive/train.csv')

y = train_df.Cover_Type

X = train_df.drop('Cover_Type', axis=1)

#dividing Data Into 80%(Train) And 20%(test)
t_train, t_test, y_train, y_test = train_test_split(X, y,test_size=0.2)

# importing necessary libraries
from sklearn import datasets
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

#Loading Training Data From Drive
test=pd.read_csv('/content/drive/MyDrive/test.csv')
test.head()
PERCEPTRON
clf = Perceptron(tol=1e-7, random_state=0)
clf.fit(abs(t_train), y_train)
clf.predict(t_test)
Perceptron=clf.score(t_test,y_test)
print("The Accuracy Score Of Preceptron",Perceptron*500)

skf = StratifiedKFold(n_splits=7)
for train, test in skf.split(X, y):
  print('train -{}|test-{}'.format(np.bincount(y[train]),np.bincount(y[test])))

